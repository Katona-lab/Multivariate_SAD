{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/python\n",
    "#\n",
    "# (c) 2017 Gergely Katona <gergely.katona@gu.se>\n",
    "#\n",
    "# Reference: Garcia-Bonete MJ, Katona G. Bayesian machine learning improves single-wavelength anomalous diffraction phasing. Acta Cryst A. 2019;75:851-60.\n",
    "#\n",
    "\n",
    "import sys\n",
    "import numpy\n",
    "import scipy\n",
    "import os\n",
    "import shutil\n",
    "import scipy.stats\n",
    "import scipy.integrate\n",
    "import pymc3 as pm\n",
    "import scipy as sp\n",
    "from theano import tensor as T\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import iotbx\n",
    "from cctbx.array_family import flex\n",
    "from cctbx import crystal\n",
    "from cctbx import uctbx\n",
    "from cctbx import sgtbx\n",
    "from cctbx import miller\n",
    "from iotbx import reflection_file_reader, mtz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initializecrystal():\n",
    "    unit_cell=( 79.07,    79.07,    36.98,  90.000,  90.000,  90.000 )       \n",
    "    uc = uctbx.unit_cell(unit_cell)\n",
    "    wavelength = 1.54980\n",
    "    xtal_symm = crystal.symmetry(unit_cell=unit_cell, space_group_symbol=\"P 43 21 2\")\n",
    "\n",
    "    ms = miller.build_set(crystal_symmetry=xtal_symm,anomalous_flag=True, d_min=1.61)\n",
    "    msnam = miller.build_set(crystal_symmetry=xtal_symm,anomalous_flag=False, d_min=1.61)\n",
    "\n",
    "    mscent=list(ms.select_centric().indices())\n",
    "    msacent=list(ms.select_acentric().indices())\n",
    "    msnamacent=list(msnam.select_acentric().indices())\n",
    "    dstar=msnam.d_star_sq()\n",
    "    msnamacent_dstar=list(dstar.select_acentric().data())\n",
    "    msnamcent=list(msnam.select_centric().indices())\n",
    "    return ms,msnam,mscent,msacent,msnamacent,msnamcent,msnamacent_dstar\n",
    "\n",
    "ms,msnam,mscent,msacent,msnamacent,msnamcent,msnamacent_dstar=initializecrystal()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File1 read in\n",
      "File2 read in\n"
     ]
    }
   ],
   "source": [
    "#Inverse treatment\n",
    "def readset(roots):\n",
    "    trows=[]\n",
    "\n",
    "    for root in roots:\n",
    "        drows=[]\n",
    "        ms,msnam,mscent,msacent,msnamacent,msnamcent,msnamacent_dstar=initializecrystal()\n",
    "        \n",
    "        data1=iotbx.xds.read_ascii.reader(open(root+\"_run1.hkl\"))\n",
    "        data2=iotbx.xds.read_ascii.reader(open(root+\"_run2.hkl\"))\n",
    "\n",
    "        inten1=data1.as_miller_array(merge_equivalents=False).as_anomalous_array()\n",
    "        batch1=data1.batch_as_miller_array().as_anomalous_array()\n",
    "\n",
    "        inten2=data2.as_miller_array(merge_equivalents=False).as_anomalous_array()\n",
    "        batch2=data2.batch_as_miller_array().as_anomalous_array()\n",
    "\n",
    "        mapinten1=inten1.map_to_asu()\n",
    "        #print list(mapinten1)\n",
    "        mapbatch1=batch1.map_to_asu()\n",
    "\n",
    "        mapinten2=inten2.map_to_asu()\n",
    "        mapbatch2=batch2.map_to_asu()\n",
    "\n",
    "        #data.zd.as_numpy_array()\n",
    "\n",
    "        liinten1=list(mapinten1)\n",
    "        libatch1=list(mapbatch1)\n",
    "\n",
    "        liinten2=list(mapinten2)\n",
    "        libatch2=list(mapbatch2)\n",
    "\n",
    "        prezipref1=zip(liinten1,libatch1)\n",
    "        prezipref2=zip(liinten2,libatch2)\n",
    "\n",
    "\n",
    "        for idx,odd in enumerate(prezipref1):\n",
    "            drow={'hkl':odd[0][0],\n",
    "                          'I':odd[0][1],\n",
    "                          'SIGI':odd[0][2],\n",
    "                          'batch':odd[1][1],\n",
    "                          'idx': idx,\n",
    "                          'face': 'h',\n",
    "                          'root':root,\n",
    "                          'treated': False\n",
    "                         }\n",
    "            drows.append(drow)\n",
    "        print (\"File1 read in\")\n",
    "\n",
    "        for idx,even in enumerate(prezipref2):\n",
    "            drow={'hkl':even[0][0],\n",
    "                          'I':even[0][1],\n",
    "                          'SIGI':even[0][2],\n",
    "                          'batch':even[1][1],\n",
    "                          'idx': idx,\n",
    "                          'face': 't',\n",
    "                          'root':root,\n",
    "                          'treated': False\n",
    "                         }\n",
    "            drows.append(drow)\n",
    "            \n",
    "        print (\"File2 read in\")\n",
    "        df = pd.DataFrame(drows)\n",
    "\n",
    "# Paired one way\n",
    "\n",
    "        i=0\n",
    "        for etind in msnamacent:\n",
    "            invetind=tuple([-1*x for x in etind])\n",
    "            for item1 in df[(df.hkl==etind)&(df.face=='h')&(df.treated==False)&(df.SIGI>0)].index.tolist():\n",
    "                try:\n",
    "                    tempf=abs(df[(df.hkl==invetind)&(df.face=='t')&(df.treated==False)&(df.SIGI>0)].batch-df.iloc[item1].batch)\n",
    "                    item2=tempf.idxmin\n",
    "                    if abs(df.iloc[item1].batch-df.iloc[item2].batch)<10:\n",
    "                        trow={\n",
    "                          'hkl':df.iloc[item1].hkl,\n",
    "                          'Iplus':df.iloc[item1].I,\n",
    "                          'SIGIplus':df.iloc[item1].SIGI,\n",
    "                          'batchplus':df.iloc[item1].batch,\n",
    "                          'Iminus':df.iloc[item2].I,\n",
    "                          'SIGIminus':df.iloc[item2].SIGI,\n",
    "                          'batchminus':df.iloc[item2].batch,\n",
    "                          'root':df.iloc[item1].root,\n",
    "                          'paired':'pair',\n",
    "                         }\n",
    "                        trows.append(trow)\n",
    "                        df.set_value(item1,'treated',True)\n",
    "                        df.set_value(item2,'treated',True)\n",
    "                        i=i+1\n",
    "                except:\n",
    "                    pass\n",
    "                \n",
    "        print (\"Phase 1 completed\")\n",
    "\n",
    "# Paired reverse\n",
    "\n",
    "        for etind in msnamacent:\n",
    "            invetind=tuple([-1*x for x in etind])\n",
    "            for item1 in df[(df.hkl==invetind)&(df.face=='h')&(df.treated==False)&(df.SIGI>0)].index.tolist():\n",
    "                try:\n",
    "                    tempf=abs(df[(df.hkl==etind)&(df.face=='t')&(df.treated==False)&(df.SIGI>0)].batch-df.iloc[item1].batch)\n",
    "                    item2=tempf.idxmin\n",
    "\n",
    "                    if abs(df.iloc[item1].batch-df.iloc[item2].batch)<10:\n",
    "                        trow={\n",
    "                          'hkl':df.iloc[item2].hkl,\n",
    "                          'Iplus':df.iloc[item2].I,\n",
    "                          'SIGIplus':df.iloc[item2].SIGI,\n",
    "                          'batchplus':df.iloc[item2].batch,\n",
    "                          'Iminus':df.iloc[item1].I,\n",
    "                          'SIGIminus':df.iloc[item1].SIGI,\n",
    "                          'batchminus':df.iloc[item1].batch,\n",
    "                          'root':df.iloc[item1].root,\n",
    "                          'paired':'pair',\n",
    "                         }\n",
    "                        trows.append(trow)\n",
    "                        df.set_value(item1,'treated',True)\n",
    "                        df.set_value(item2,'treated',True)\n",
    "                        i=i+1\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "        print (\"Phase 2 completed\")\n",
    "                \n",
    "# Solos +\n",
    "\n",
    "        for etind in msnamacent:\n",
    "            invetind=tuple([-1*x for x in etind])\n",
    "            for item1 in df[(df.hkl==etind)&(df.treated==False)&(df.SIGI>0)].index.tolist():\n",
    "                trow={\n",
    "                      'hkl':df.iloc[item1].hkl,\n",
    "                      'Iplus':df.iloc[item1].I,\n",
    "                      'SIGIplus':df.iloc[item1].SIGI,\n",
    "                      'batchplus':df.iloc[item1].batch,\n",
    "                      'root':df.iloc[item1].root,\n",
    "                      'paired':'plus',\n",
    "                         }\n",
    "                trows.append(trow)\n",
    "                df.set_value(item1,'treated',True)\n",
    "\n",
    "# Solos - \n",
    "\n",
    "        for etind in msnamacent:\n",
    "            invetind=tuple([-1*x for x in etind])\n",
    "            for item1 in df[(df.hkl==invetind)&(df.treated==False)&(df.SIGI>0)].index.tolist():\n",
    "                trow={\n",
    "                      'hkl':df.iloc[item1].hkl,\n",
    "                      'Iminus':df.iloc[item1].I,\n",
    "                      'SIGIminus':df.iloc[item1].SIGI,\n",
    "                      'batchminus':df.iloc[item1].batch,\n",
    "                      'root':df.iloc[item1].root,\n",
    "                      'paired':'minus',\n",
    "                         }\n",
    "                trows.append(trow)\n",
    "                df.set_value(item1,'treated',True)\n",
    "\n",
    "                        \n",
    "# Centric - \n",
    "\n",
    "        for etind in mscent:\n",
    "            for item1 in df[(df.hkl==etind)&(df.treated==False)&(df.SIGI>0)].index.tolist():\n",
    "                trow={\n",
    "                          'hkl':df.iloc[item1].hkl,\n",
    "                          'Icent':df.iloc[item1].I,\n",
    "                          'SIGIcent':df.iloc[item1].SIGI,\n",
    "                          'batchcent':df.iloc[item1].batch,\n",
    "                          'root':df.iloc[item1].root,\n",
    "                          'paired':'cent',\n",
    "                         }\n",
    "                trows.append(trow)\n",
    "                df.set_value(item1,'treated',True)\n",
    "\n",
    "                        \n",
    "        print (root+\" completed! Found matching reflections:\"+str(i)+\".\")\n",
    "    \n",
    "    tf = pd.DataFrame(trows)\n",
    "    return tf\n",
    "\n",
    "GHz400=['inverse1','inverse2','inverse3','inverse4']\n",
    "GHz400.sort()\n",
    "tf =readset(GHz400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File1 read in\n",
      "Phase 1 completed\n",
      "Phase 2 completed\n",
      "File1 read in\n",
      "Phase 1 completed\n",
      "Phase 2 completed\n",
      "File1 read in\n",
      "Phase 1 completed\n",
      "Phase 2 completed\n",
      "File1 read in\n",
      "Phase 1 completed\n",
      "Phase 2 completed\n",
      "File1 read in\n",
      "Phase 1 completed\n",
      "Phase 2 completed\n",
      "cont6 completed! Found matching reflections:67627.\n"
     ]
    }
   ],
   "source": [
    "# Continuous treatment for Bijvoet pairs!\n",
    "exptype='CONT'\n",
    "def readset(roots):\n",
    "    \n",
    "    trows=[]\n",
    "\n",
    "    for root in roots:\n",
    "        drows=[]\n",
    "\n",
    "        ms,msnam,mscent,msacent,msnamacent,msnamcent,msnamacent_dstar=initializecrystal()\n",
    "        \n",
    "        data1=iotbx.xds.read_ascii.reader(open(root+\".hkl\"))\n",
    "\n",
    "        inten1=data1.as_miller_array(merge_equivalents=False).as_anomalous_array()\n",
    "        batch1=data1.batch_as_miller_array().as_anomalous_array()\n",
    "\n",
    "\n",
    "\n",
    "        mapinten1=inten1.map_to_asu()\n",
    "        mapbatch1=batch1.map_to_asu()\n",
    "\n",
    "\n",
    "\n",
    "        liinten1=list(mapinten1)\n",
    "        libatch1=list(mapbatch1)\n",
    "\n",
    "\n",
    "        prezipref1=zip(liinten1,libatch1)\n",
    "\n",
    "\n",
    "        for idx,odd in enumerate(prezipref1):\n",
    "            drow={'hkl':odd[0][0],\n",
    "                          'I':odd[0][1],\n",
    "                          'SIGI':odd[0][2],\n",
    "                          'batch':odd[1][1],\n",
    "                          'idx': idx,\n",
    "                          'root':root,\n",
    "                          'treated': False\n",
    "                         }\n",
    "            drows.append(drow)\n",
    "        print (\"File1 read in\")\n",
    "\n",
    "\n",
    "        df = pd.DataFrame(drows)\n",
    "\n",
    "# Paired one way\n",
    "\n",
    "        i=0\n",
    "        for etind in msnamacent:\n",
    "            invetind=tuple([-1*x for x in etind])\n",
    "            for item1 in df[(df.hkl==etind)&(df.treated==False)&(df.SIGI>0)].index.tolist():\n",
    "                try:\n",
    "                    tempf=abs(df[(df.hkl==invetind)&(df.root==df.iloc[item1].root)&(df.treated==False)&(df.SIGI>0)].batch-df.iloc[item1].batch)\n",
    "                    item2=tempf.idxmin\n",
    "                    if abs(df.iloc[item1].batch-df.iloc[item2].batch)<100:\n",
    "                        trow={\n",
    "                          'hkl':etind,\n",
    "                          'Iplus':df.iloc[item1].I,\n",
    "                          'SIGIplus':df.iloc[item1].SIGI,\n",
    "                          'batchplus':df.iloc[item1].batch,\n",
    "                          'Iminus':df.iloc[item2].I,\n",
    "                          'SIGIminus':df.iloc[item2].SIGI,\n",
    "                          'batchminus':df.iloc[item2].batch,\n",
    "                          'root':df.iloc[item1].root,\n",
    "                          'paired':'pair',\n",
    "                         }\n",
    "                        trows.append(trow)\n",
    "                        df.set_value(item1,'treated',True)\n",
    "                        df.set_value(item2,'treated',True)\n",
    "                        i=i+1\n",
    "                except:\n",
    "                    pass\n",
    "                \n",
    "        print (\"Phase 1 completed\")\n",
    "\n",
    "# Paired reverse\n",
    "\n",
    "        for etind in msnamacent:\n",
    "            invetind=tuple([-1*x for x in etind])\n",
    "            for item1 in df[(df.hkl==invetind)&(df.treated==False)&(df.SIGI>0)].index.tolist():\n",
    "                try:\n",
    "                    tempf=abs(df[(df.hkl==etind)&(df.root==df.iloc[item1].root)&(df.treated==False)&(df.SIGI>0)].batch-df.iloc[item1].batch)\n",
    "                    item2=tempf.idxmin\n",
    "\n",
    "                    if abs(df.iloc[item1].batch-df.iloc[item2].batch)<100:\n",
    "                        trow={\n",
    "                          'hkl':etind,\n",
    "                          'Iplus':df.iloc[item2].I,\n",
    "                          'SIGIplus':df.iloc[item2].SIGI,\n",
    "                          'batchplus':df.iloc[item2].batch,\n",
    "                          'Iminus':df.iloc[item1].I,\n",
    "                          'SIGIminus':df.iloc[item1].SIGI,\n",
    "                          'batchminus':df.iloc[item1].batch,\n",
    "                          'root':df.iloc[item1].root,\n",
    "                          'paired':'pair',\n",
    "                         }\n",
    "                        trows.append(trow)\n",
    "                        df.set_value(item1,'treated',True)\n",
    "                        df.set_value(item2,'treated',True)\n",
    "                        i=i+1\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "        print (\"Phase 2 completed\")\n",
    "                \n",
    "# Solos +\n",
    "\n",
    "        for etind in msnamacent:\n",
    "            invetind=tuple([-1*x for x in etind])\n",
    "            for item1 in df[(df.hkl==etind)&(df.treated==False)&(df.SIGI>0)].index.tolist():\n",
    "                trow={\n",
    "                      'hkl':etind,\n",
    "                      'Iplus':df.iloc[item1].I,\n",
    "                      'SIGIplus':df.iloc[item1].SIGI,\n",
    "                      'batchplus':df.iloc[item1].batch,\n",
    "                      'root':df.iloc[item1].root,\n",
    "                      'paired':'plus',\n",
    "                         }\n",
    "                trows.append(trow)\n",
    "                df.set_value(item1,'treated',True)\n",
    "\n",
    "# Solos - \n",
    "\n",
    "        for etind in msnamacent:\n",
    "            invetind=tuple([-1*x for x in etind])\n",
    "            for item1 in df[(df.hkl==invetind)&(df.treated==False)&(df.SIGI>0)].index.tolist():\n",
    "                trow={\n",
    "                      'hkl':etind,\n",
    "                      'Iminus':df.iloc[item1].I,\n",
    "                      'SIGIminus':df.iloc[item1].SIGI,\n",
    "                      'batchminus':df.iloc[item1].batch,\n",
    "                      'root':df.iloc[item1].root,\n",
    "                      'paired':'minus',\n",
    "                         }\n",
    "                trows.append(trow)\n",
    "                df.set_value(item1,'treated',True)\n",
    "\n",
    "# Centric - \n",
    "\n",
    "        for etind in msnamcent:\n",
    "            for item1 in df[(df.hkl==etind)&(df.treated==False)&(df.SIGI>0)].index.tolist():\n",
    "                trow={\n",
    "                          'hkl':etind,\n",
    "                          'Icent':df.iloc[item1].I,\n",
    "                          'SIGIcent':df.iloc[item1].SIGI,\n",
    "                          'batchcent':df.iloc[item1].batch,\n",
    "                          'root':df.iloc[item1].root,\n",
    "                          'paired':'cent',\n",
    "                         }\n",
    "                trows.append(trow)\n",
    "                df.set_value(item1,'treated',True)\n",
    "\n",
    "        print (root+\" completed! Found matching reflections:\"+str(i)+\".\")\n",
    "    \n",
    "    tf = pd.DataFrame(trows)\n",
    "    return (tf)\n",
    "\n",
    "datasets=['cont2','cont3','cont4','cont5','cont6']\n",
    "datasets.sort()\n",
    "tf =readset(datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File1 read in\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gergely/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:69: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "/home/gergely/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:70: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phase 1 completed\n",
      "Phase 2 completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gergely/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:120: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "/home/gergely/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:136: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "/home/gergely/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:151: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cont2 completed! Found matching reflections:132943.\n",
      "File1 read in\n",
      "Phase 1 completed\n",
      "Phase 2 completed\n",
      "cont3 completed! Found matching reflections:124439.\n",
      "File1 read in\n",
      "Phase 1 completed\n",
      "Phase 2 completed\n",
      "cont4 completed! Found matching reflections:113281.\n",
      "File1 read in\n",
      "Phase 1 completed\n",
      "Phase 2 completed\n",
      "cont5 completed! Found matching reflections:109072.\n",
      "File1 read in\n",
      "Phase 1 completed\n",
      "Phase 2 completed\n",
      "cont6 completed! Found matching reflections:113161.\n"
     ]
    }
   ],
   "source": [
    "# Continuous treatment, but pairing Friedels!!!\n",
    "exptype='CONT'\n",
    "def readset(roots):\n",
    "    \n",
    "    trows=[]\n",
    "\n",
    "    for root in roots:\n",
    "        drows=[]\n",
    "\n",
    "        ms,msnam,mscent,msacent,msnamacent,msnamcent,msnamacent_dstar=initializecrystal()\n",
    "        \n",
    "        data1=iotbx.xds.read_ascii.reader(open(root+\".hkl\"))\n",
    "\n",
    "        inten1=data1.as_miller_array(merge_equivalents=False).as_anomalous_array()\n",
    "        batch1=data1.batch_as_miller_array().as_anomalous_array()\n",
    "\n",
    "        mapinten1=inten1.map_to_asu()\n",
    "        mapbatch1=batch1.map_to_asu()\n",
    "\n",
    "        liinten1=list(mapinten1)\n",
    "        libatch1=list(mapbatch1)\n",
    "\n",
    "        prezipref1=zip(liinten1,libatch1)\n",
    "\n",
    "        for idx,odd in enumerate(prezipref1):\n",
    "            drow={'hkl':odd[0][0],\n",
    "                          'I':odd[0][1],\n",
    "                          'SIGI':odd[0][2],\n",
    "                          'batch':odd[1][1],\n",
    "                          'idx': idx,\n",
    "                          'root':root,\n",
    "#                          'cent': odd[0][0] in mscent,\n",
    "                          'treated': False\n",
    "                         }\n",
    "            drows.append(drow)\n",
    "        print (\"File1 read in\")\n",
    "\n",
    "        df = pd.DataFrame(drows)\n",
    "\n",
    "# Paired one way\n",
    "\n",
    "        i=0\n",
    "        for etind in msnamacent:\n",
    "            invetind=tuple([-1*x for x in etind])\n",
    "            for item1 in df[(df.hkl==etind)&(df.treated==False)&(df.SIGI>0)].index.tolist():\n",
    "                try:\n",
    "                    tempf=abs(abs(df[(df.hkl==invetind)&(df.root==df.iloc[item1].root)&(df.treated==False)&(df.SIGI>0)].batch-df.iloc[item1].batch)-1800)\n",
    "                    item2=tempf.idxmin\n",
    "                    if abs(abs(df.iloc[item1].batch-df.iloc[item2].batch)-1800)<10:\n",
    "                        trow={\n",
    "                          'hkl':etind,\n",
    "                          'Iplus':df.iloc[item1].I,\n",
    "                          'SIGIplus':df.iloc[item1].SIGI,\n",
    "                          'batchplus':df.iloc[item1].batch,\n",
    "                          'Iminus':df.iloc[item2].I,\n",
    "                          'SIGIminus':df.iloc[item2].SIGI,\n",
    "                          'batchminus':df.iloc[item2].batch,\n",
    "                          'root':df.iloc[item1].root,\n",
    "                          'paired':'pair',\n",
    "                         }\n",
    "                        trows.append(trow)\n",
    "                        df.set_value(item1,'treated',True)\n",
    "                        df.set_value(item2,'treated',True)\n",
    "                        i=i+1\n",
    "                except:\n",
    "                    pass\n",
    "                \n",
    "        print (\"Phase 1 completed\")\n",
    "\n",
    "# Paired reverse\n",
    "\n",
    "        for etind in msnamacent:\n",
    "            invetind=tuple([-1*x for x in etind])\n",
    "            for item1 in df[(df.hkl==invetind)&(df.treated==False)&(df.SIGI>0)].index.tolist():\n",
    "                try:\n",
    "                    tempf=abs(abs(df[(df.hkl==etind)&(df.root==df.iloc[item1].root)&(df.treated==False)&(df.SIGI>0)].batch-df.iloc[item1].batch)-1800)\n",
    "                    item2=tempf.idxmin\n",
    "                    if abs(abs(df.iloc[item1].batch-df.iloc[item2].batch)-1800)<10:\n",
    "                        trow={\n",
    "                          'hkl':etind,\n",
    "                          'Iplus':df.iloc[item2].I,\n",
    "                          'SIGIplus':df.iloc[item2].SIGI,\n",
    "                          'batchplus':df.iloc[item2].batch,\n",
    "                          'Iminus':df.iloc[item1].I,\n",
    "                          'SIGIminus':df.iloc[item1].SIGI,\n",
    "                          'batchminus':df.iloc[item1].batch,\n",
    "                          'root':df.iloc[item1].root,\n",
    "                          'paired':'pair',\n",
    "                         }\n",
    "                        trows.append(trow)\n",
    "                        df.set_value(item1,'treated',True)\n",
    "                        df.set_value(item2,'treated',True)\n",
    "                        i=i+1\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "        print (\"Phase 2 completed\")\n",
    "                \n",
    "# Solos +\n",
    "\n",
    "        for etind in msnamacent:\n",
    "            invetind=tuple([-1*x for x in etind])\n",
    "            for item1 in df[(df.hkl==etind)&(df.treated==False)&(df.SIGI>0)].index.tolist():\n",
    "                trow={\n",
    "                      'hkl':etind,\n",
    "                      'Iplus':df.iloc[item1].I,\n",
    "                      'SIGIplus':df.iloc[item1].SIGI,\n",
    "                      'batchplus':df.iloc[item1].batch,\n",
    "                      'root':df.iloc[item1].root,\n",
    "                      'paired':'plus',\n",
    "                         }\n",
    "                trows.append(trow)\n",
    "                df.set_value(item1,'treated',True)\n",
    "\n",
    "# Solos - \n",
    "\n",
    "        for etind in msnamacent:\n",
    "            invetind=tuple([-1*x for x in etind])\n",
    "            for item1 in df[(df.hkl==invetind)&(df.treated==False)&(df.SIGI>0)].index.tolist():\n",
    "                trow={\n",
    "                      'hkl':etind,\n",
    "                      'Iminus':df.iloc[item1].I,\n",
    "                      'SIGIminus':df.iloc[item1].SIGI,\n",
    "                      'batchminus':df.iloc[item1].batch,\n",
    "                      'root':df.iloc[item1].root,\n",
    "                      'paired':'minus',\n",
    "                         }\n",
    "                trows.append(trow)\n",
    "                df.set_value(item1,'treated',True)\n",
    "\n",
    "# Centric - \n",
    "\n",
    "        for etind in msnamcent:\n",
    "            for item1 in df[(df.hkl==etind)&(df.treated==False)&(df.SIGI>0)].index.tolist():\n",
    "                trow={\n",
    "                          'hkl':etind,\n",
    "                          'Icent':df.iloc[item1].I,\n",
    "                          'SIGIcent':df.iloc[item1].SIGI,\n",
    "                          'batchcent':df.iloc[item1].batch,\n",
    "                          'root':df.iloc[item1].root,\n",
    "                          'paired':'cent',\n",
    "                         }\n",
    "                trows.append(trow)\n",
    "                df.set_value(item1,'treated',True)\n",
    "\n",
    "        print (root+\" completed! Found matching reflections:\"+str(i)+\".\")\n",
    "    \n",
    "    tf = pd.DataFrame(trows)\n",
    "    return (tf)\n",
    "\n",
    "datasets=['cont2','cont3','cont4','cont5','cont6']\n",
    "datasets.sort()\n",
    "tf =readset(datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multidiff(refl):           \n",
    "    with pm.Model() as model:\n",
    "        quality=0\n",
    "        F = pm.Uniform('F',0,1e8,shape=2)\n",
    "        sigma = pm.Lognormal('sigma', 0, 1,shape=2)\n",
    "\n",
    "        Fdel = pm.Deterministic('Fdel',F[0]-F[1])\n",
    "        Fmean = pm.Deterministic('Fmean',(F[0]+F[1])/2.0)\n",
    "        Effect = pm.Deterministic('Effect',(F[0]**2-F[1]**2)/pm.math.sqrt(sigma[0]**2+sigma[1]**2))\n",
    "\n",
    "        C_t = pm.LKJCorr('C_t', 1, 2) \n",
    "        C = pm.Deterministic('C', T.fill_diagonal(C_t[np.zeros((2, 2), dtype=np.int64)], 1.))\n",
    "    \n",
    "        sigma_diag = pm.Deterministic('sigma_mat', T.nlinalg.diag(sigma))\n",
    "        cov = pm.Deterministic('cov', T.nlinalg.matrix_dot(sigma_diag, C, sigma_diag))\n",
    "        obsMV = pm.MvNormal('MV',pm.math.sqr(F),cov=cov, observed=tf[(tf.hkl==(refl))&(tf.paired=='pair')][['Iplus','Iminus']])\n",
    "\n",
    "\n",
    "    with model:\n",
    "        step = pm.Metropolis()\n",
    "        trace = pm.sample(10000,tune=40000,step=step, progressbar=True)\n",
    "\n",
    "    return trace\n",
    "\n",
    "def uni(refl, rtype):\n",
    "    itype={}\n",
    "    itype['cent']='Icent'\n",
    "    itype['plus']='Iplus'\n",
    "    itype['minus']='Iminus'\n",
    "    \n",
    "    with pm.Model() as model:\n",
    "        F = pm.Uniform('F',0,1e8)    \n",
    "        sigma = pm.Lognormal('sigma', 0, 1)\n",
    "        Fmean = pm.Deterministic('Fmean',F)\n",
    "\n",
    "        obs = pm.Normal('obs',pm.math.sqr(F),sd=sigma, observed=tf[(tf.hkl==(refl))&(tf.paired==rtype)][[itype[rtype]]])\n",
    "\n",
    "    with model:\n",
    "        step = pm.Metropolis()\n",
    "        trace_ = pm.sample(50000, step, progressbar=True)\n",
    "        trace = trace_[40000:]\n",
    "        \n",
    "    return trace\n",
    " \n",
    "def unidiff(refl):\n",
    "    with pm.Model() as model:\n",
    "        F = pm.Uniform('F',0,1e8,shape=2)  \n",
    "        sigma = pm.Lognormal('sigma', 0, 1)\n",
    "        Fmean = pm.Deterministic('Fmean',F)\n",
    "        Fdel = pm.Deterministic('Fdel',F[0]-F[1])\n",
    "        Effect = pm.Deterministic('Effect',(F[0]**2-F[1]**2)/sigma)\n",
    "        \n",
    "        obsplus = pm.Normal('Plus',pm.math.sqr(F[0]),sd=sigma, observed=tf[(tf.hkl==(refl))][['Iplus']])\n",
    "        obsminus = pm.Normal('Minus',pm.math.sqr(F[1]),sd=sigma, observed=tf[(tf.hkl==(refl))][['Iminus']])\n",
    "\n",
    "    with model:\n",
    "        step = pm.Metropolis()\n",
    "        trace_ = pm.sample(50000, step, progressbar=True)\n",
    "        trace = trace_[40000:]\n",
    "\n",
    "    return trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "ms,msnam,mscent,msacent,msnamacent=initializecrystal()\n",
    "\n",
    "for refl in msnamacent:\n",
    "    if tf[(tf.hkl==(refl))].shape[0]==0:\n",
    "        print (\"No acentric reflection!\")        \n",
    "    elif (tf[(tf.hkl==(refl))&(tf.paired=='pair')].shape[0]==0) & (tf[(tf.hkl==(refl))&(tf.paired=='minus')].shape[0]==0):\n",
    "        trace=uni(refl,'plus')\n",
    "#        f.write(str(refl[0])+','+str(refl[1])+','+str(refl[2]))\n",
    "        with open('workfile.hkl', 'a') as f:\n",
    "            f.write('%6d,%6d,%6d,' % (refl))\n",
    "            f.write('%10.3E,%10.3E,' % (np.median(trace['Fmean']),np.std(trace['Fmean'])))\n",
    "            f.write(',,,')\n",
    "            f.write('1,0\\n')        \n",
    "        print (\"Unirun\")\n",
    "        sys.stderr.write(str(refl)+\" \"+str(np.median(trace['Fmean']))+\" \"+\"plus\"+\"\\n\")\n",
    "    elif (tf[(tf.hkl==(refl))&(tf.paired=='pair')].shape[0]==0) & (tf[(tf.hkl==(refl))&(tf.paired=='plus')].shape[0]==0):\n",
    "        trace=uni(refl,'minus')\n",
    "        with open('workfile.hkl', 'a') as f:\n",
    "            f.write('%6d,%6d,%6d,' % (refl))\n",
    "            f.write('%10.3E,%10.3E,' % (np.median(trace['Fmean']),np.std(trace['Fmean'])))\n",
    "            f.write(',,,')\n",
    "            f.write('2,0\\n')\n",
    "        print (\"Unirun\")\n",
    "        sys.stderr.write(str(refl)+\" \"+str(np.median(trace['Fmean']))+\" \"+\"minus\"+\"\\n\")\n",
    "    elif tf[(tf.hkl==(refl))&(tf.paired=='pair')].shape[0]>=3:\n",
    "        trace=multidiff(refl)\n",
    "        with open('workfile.hkl', 'a') as f:\n",
    "            f.write('%6d,%6d,%6d,' % (refl))\n",
    "            f.write('%10.3E,%10.3E,' % (np.median(trace['Fmean']),np.std(trace['Fmean'])))\n",
    "            f.write('%10.3E,%10.3E,' % (np.median(trace['Fdel']),np.std(trace['Fdel'])))\n",
    "            f.write('0,0\\n')\n",
    "        with open('miscfile.hkl', 'a') as f:\n",
    "            f.write('%6d,%6d,%6d,' % (refl))\n",
    "            f.write('%10.3E,%10.3E,' % (np.median(trace['C_t']),np.std(trace['C_t'])))\n",
    "            f.write('%10.3E,%10.3E,' % (np.median(trace['Effect']),np.std(trace['Effect'])))\n",
    "            f.write('%10.3E,%10.3E' % (np.median(trace['Fdel'])/np.std(trace['Fdel']),pm.autocorr(trace['Fdel'],lag=100)))\n",
    "            f.write('\\n')\n",
    "        print (\"Multirun\")\n",
    "        sys.stderr.write(str(refl)+\" \"+str(np.median(trace['Fdel']))+\" \"+str(np.median(trace['Effect']))+\"\\n\")\n",
    "    elif tf[(tf.hkl==(refl))&(tf.paired=='pair')].shape[0]<3:\n",
    "        trace=unidiff(refl)\n",
    "        with open('workfile.hkl', 'a') as f:\n",
    "            f.write('%6d,%6d,%6d,' % (refl))\n",
    "            f.write('%10.3E,%10.3E,' % (np.median(trace['Fmean']),np.std(trace['Fmean'])))\n",
    "            f.write('%10.3E,%10.3E,' % (np.median(trace['Fdel']),np.std(trace['Fdel'])))\n",
    "            f.write('0,0\\n')\n",
    "        with open('miscfile.hkl', 'a') as f:\n",
    "            f.write('%6d,%6d,%6d,' % (refl))\n",
    "            f.write(',,' )\n",
    "            f.write('%10.3E,%10.3E,' % (np.median(trace['Effect']),np.std(trace['Effect'])))\n",
    "            f.write('%10.3E,%10.3E' % (np.median(trace['Fdel'])/np.std(trace['Fdel']),pm.autocorr(trace['Fdel'],lag=100)))\n",
    "            f.write('\\n')\n",
    "        print (\"Unipairrun\")\n",
    "        sys.stderr.write(str(refl)+\" \"+str(np.median(trace['Fdel']))+\" \"+str(np.median(trace['Effect']))+\"\\n\")\n",
    "\n",
    "for refl in mscent:\n",
    "    if tf[(tf.hkl==(refl))].shape[0]==0:\n",
    "        print (\"No centric reflection!\")\n",
    "    else:\n",
    "        trace=uni(refl,'cent')\n",
    "        with open('workfile.hkl', 'a') as f:\n",
    "            f.write('%6d,%6d,%6d,' % (refl))\n",
    "            f.write('%10.3E,%10.3E,' % (np.median(trace['Fmean']),np.std(trace['Fmean'])))\n",
    "            f.write('%10.3E,%10.3E,' % (0.0,0.0))\n",
    "            f.write('0,0\\n')\n",
    "        print (\"Unirun\")\n",
    "        sys.stderr.write(str(refl)+\" \"+str(np.median(trace['Fmean']))+\" \"+\"cent\"+\"\\n\")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
